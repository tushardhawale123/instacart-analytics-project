# Instacart Online Grocery Analysis

![Project Banner](4_visualizations/screenshots/project_banner.png)

## Project Overview

This end-to-end data engineering and analytics project analyzes Instacart online grocery shopping data to uncover customer purchasing patterns, product performance, and shopping behaviors. By examining over 3 million grocery orders from more than 200,000 Instacart users, this project delivers actionable insights through interactive Power BI dashboards aimed at optimizing inventory management, marketing strategies, and enhancing the overall customer experience.

## ğŸ“Š Dashboard Screenshots

### Executive Overview Dashboard
![Executive Overview](4_visualizations/screenshots/executive_overview.png)

### Customer Analysis Dashboard
![Customer Analysis](4_visualizations/screenshots/customer_analysis.png)

### Product Analysis Dashboard
![Product Analysis](4_visualizations/screenshots/product_analysis.png)

## âš ï¸ Important Note on Data Files

**Due to GitHub's file size limitations, the raw data files (exceeding 100MB) could not be uploaded to this repository.**

To reproduce this analysis, please download the "Instacart Market Basket Analysis" dataset from Kaggle:
[https://www.kaggle.com/datasets/yasserh/instacart-online-grocery-basket-analysis-dataset?resource=download](https://www.kaggle.com/datasets/yasserh/instacart-online-grocery-basket-analysis-dataset)

Place the downloaded CSV files in the `1_data/raw/` directory before running any scripts.

## ğŸ“‚ Repository Structure

```
instacart-analytics-project/
â”œâ”€â”€ 1_data/                  # Raw and processed data files
â”‚   â”œâ”€â”€ raw/                 # Original Kaggle dataset
â”‚   â””â”€â”€ processed/           # Cleaned and transformed data
â”‚
â”œâ”€â”€ 2_code/                  # All code files
â”‚   â”œâ”€â”€ python/              # Python scripts (PyCharm)
â”‚   â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”‚   â”œâ”€â”€ exploratory_analysis.py
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”‚
â”‚   â”œâ”€â”€ sql/                 # SQL scripts (SSMS)
â”‚   â”‚   â”œâ”€â”€ schema_creation.sql
â”‚   â”‚   â”œâ”€â”€ data_loading.sql
â”‚   â”‚   â””â”€â”€ analysis_queries.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ pyspark/             # PySpark scripts (Docker)
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ spark_processing.py
â”‚   â”‚
â”‚   â””â”€â”€ databricks/          # Databricks notebooks
â”‚       â”œâ”€â”€ data_ingestion.py
â”‚       â”œâ”€â”€ advanced_analytics.py
â”‚       â””â”€â”€ machine_learning.py
â”‚
â”œâ”€â”€ 3_azure/                 # Azure configuration
â”‚   â””â”€â”€ arm_templates/
â”‚       â””â”€â”€ adf_pipelines/
â”‚
â”œâ”€â”€ 4_visualizations/        # Power BI files
â”‚   â”œâ”€â”€ instacart_analysis.pbix
â”‚   â””â”€â”€ dashboard_designs/
â”‚
â””â”€â”€ 5_documentation/         # Project documentation
    â”œâ”€â”€ project_overview.md
    â”œâ”€â”€ data_dictionary.md
    â”œâ”€â”€ technical_implementation.md
    â””â”€â”€ business_insights.md
```

## ğŸš€ Project Development Journey

### 1. Project Planning & Data Understanding
- Defined business objectives: understanding customer behavior, product performance, and shopping patterns
- Downloaded and explored the Instacart dataset from Kaggle
- Created project architecture and infrastructure requirements
- Developed detailed data dictionary and entity-relationship diagrams

### 2. Data Engineering Phase
- **Data Ingestion**: 
  - Set up Azure Data Factory pipelines to ingest data
  - Implemented data quality checks and error handling
  
- **Data Processing**:
  - Python scripts for data cleaning and feature engineering
  - PySpark jobs for large-scale transformations
  - SQL procedures for relational data modeling

- **Data Storage**:
  - Designed multi-layer architecture (bronze/silver/gold)
  - Optimized storage with proper partitioning and indexing

### 3. Analytical Processing
- Performed exploratory data analysis using Python/Pandas
- Developed customer segmentation model using k-means clustering
- Built product affinity analysis with association rules
- Created time-pattern analysis for order scheduling
- Applied machine learning for reorder prediction

### 4. Visualization Development
- Power BI dashboard design with three main pages:
  - Executive Overview: KPIs and high-level trends
  - Customer Analysis: Segment behavior and patterns
  - Product Analysis: Performance metrics and associations
- Implemented custom DAX measures for advanced calculations
- Optimized visuals for interactivity and performance
- Created custom tooltips and drill-through experiences

### 5. Quality Assurance & Documentation
- Performed cross-validation of calculated measures
- Fixed visualization issues and optimized DAX formulas
- Created comprehensive documentation including:
  - User guide for dashboard navigation
  - Technical implementation details
  - Data dictionary and model documentation

## ğŸ”§ Technologies Used

- **Programming Languages**: Python, SQL, DAX, M Query
- **Big Data Processing**: PySpark, Databricks
- **Cloud Services**: Azure (Data Factory, Blob Storage, SQL DB)
- **Data Analysis**: Pandas, NumPy, Scikit-learn
- **Visualization**: Power BI Desktop
- **Version Control**: Git/GitHub
- **Development Environments**: PyCharm, VS Code, SQL Server Management Studio

## ğŸ’¡ Key Insights

- **Customer Behavior**:
  - Identified 4 distinct customer segments with unique shopping patterns
  - 41% of customers show consistent weekly shopping patterns
  - New customers focus on essentials before expanding to specialty items

- **Product Performance**:
  - Fresh produce and dairy have highest reorder rates (68% and 62% respectively)
  - Certain products show strong time-of-day purchase patterns
  - Department popularity varies significantly by day of week

- **Shopping Patterns**:
  - Peak ordering hours: 10am-11am and 2pm-4pm
  - Weekend orders have 30% larger basket sizes
  - Most reorders occur within 7-10 days of previous purchase

## ğŸ Getting Started

### Prerequisites
- Python 3.8+
- SQL Server or Azure SQL
- PySpark environment or Docker
- Power BI Desktop

### Installation & Setup
1. Clone this repository
2. Download the Instacart dataset from Kaggle and place in `1_data/raw/`
3. Set up Python environment: `pip install -r 2_code/pyspark/requirements.txt`
4. Run data processing scripts in sequence:
   ```
   python 2_code/python/data_cleaning.py
   python 2_code/python/exploratory_analysis.py
   python 2_code/python/feature_engineering.py
   ```
5. Execute SQL scripts in `2_code/sql/` directory to set up database
6. Open Power BI files in `4_visualizations/` to explore dashboards

## ğŸ“ Future Enhancements

- Implement real-time data processing with Azure Stream Analytics
- Develop predictive models for inventory optimization
- Create mobile-optimized dashboard views
- Integration with customer demographic data for richer segmentation

## ğŸ‘¤ Author

- **Tushar Dhawale** - [GitHub Profile](https://github.com/tushardhawale123)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

*Last updated: May 31, 2025*
```
